{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We always start a project by importing our relevant libraries, which allows us to access pre-written commands that make our lives easier. Here, we import numpy, pandas, and matplot. \n",
    "\n",
    "Numpy: adds support for high-level mathematical functions, especially when working with arrays and matrices. \n",
    "\n",
    "Pandas: adds support for data manipulation and analysis. It is especially helpful by offering data structures and operations for manipulating numerical tables. \n",
    "\n",
    "Matplotlib: adds support for creating static, animated, and interactive visualizations (e.g. graphs). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we will import our dataset using the read_csv command. Through this command, we access the csv and convert it to a dataframe we can manipulate and work with through pandas. We first give the link to our dataset (which for now is in github). We then specify that our header is none, which means that we don't give the columns any names (yet). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/SiP-AI-ML/LessonMaterials/master/sales_data.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape method allows you to view the dimensions of your dataframe as a matrix, which you learn more about in algebra. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The head() method allows you to view the top five rows of your pandas dataframe and confirm it looks reasonable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1\n",
      "0  12.0  15.0\n",
      "1  20.5  16.0\n",
      "2  21.0  18.0\n",
      "3  15.5  27.0\n",
      "4  15.3  21.0\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will rename the columns of our python database into sales and advertising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Sales', 'Advertising']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will call the head function again to make sure that our columns were properly renamed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sales  Advertising\n",
      "0   12.0         15.0\n",
      "1   20.5         16.0\n",
      "2   21.0         18.0\n",
      "3   15.5         27.0\n",
      "4   15.3         21.0\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoting variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will declare our x value, which is our independent variable. We will take all the values from the sales column and place them into our new variable x, which allows us to specifically access the independent variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Sales'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will do the same for y. We will take all the values from the advertising column and place them into our new variable y, which allows us to specifically access the dependent variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Advertising'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will plot a simple graph between the x and y variables. This will allow us to visually see what the relationship between the independent/dependent variables look like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y, color = 'blue', label='Scatter Plot')\n",
    "plt.title('Relationship between Sales and Advertising')\n",
    "plt.xlabel('Sales')\n",
    "plt.ylabel('Advertising')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformatting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to see the dimensions of the x and y variables. They need a very specific format to be used for machine learning and the sklearn dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping X and y\n",
    "\n",
    "We will reshape this using the numpy reshape method. We will specify our first dimension to be -1, which means \"unspecified\". This value is inferred from the length of the array and the remaining dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1,1)\n",
    "y = y.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to confirm that our variable shapes are the right format. We will print these shapes to confirm this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add some stuff about why test train split is important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mechanics of the model\n",
    "\n",
    "\n",
    "I split the dataset into two sets – the training set and the test set. Then, I instantiate the regressor lm and fit it on the training set with the fit method. \n",
    "\n",
    "In this step, the model learned the relationships between the training data (X_train, y_train). \n",
    "\n",
    "Now the model is ready to make predictions on the test data (X_test). Hence, I predict on the test data using the predict method. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear model\n",
    "\n",
    "# Instantiate the linear regression object lm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "\n",
    "\n",
    "# Train the model using training data sets\n",
    "lm.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred=lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model slope and intercept term\n",
    "\n",
    "The model slope is given by lm.coef_ and model intercept term is given by lm.intercept_. \n",
    "\n",
    "The estimated model slope and intercept values are 1.60509347 and  -11.16003616.\n",
    "\n",
    "So, the equation of the fitted regression line is\n",
    "\n",
    "y = 1.60509347 * x - 11.16003616  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model slope and intercept\n",
    "\n",
    "a = lm.coef_\n",
    "b = lm.intercept_,\n",
    "print(\"Estimated model slope, a:\" , a)\n",
    "print(\"Estimated model intercept, b:\" , b) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, our fitted regression line is \n",
    "\n",
    "# y = 1.60509347 * x - 11.16003616 \n",
    "\n",
    "# That is our linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions\n",
    "\n",
    "\n",
    "I have predicted the Advertising values on first five 5 Sales datasets by writing code\n",
    "\n",
    "\n",
    "\t\tlm.predict(X) [0:5]  \n",
    "        \n",
    "\n",
    "If I remove [0:5], then I will get predicted Advertising values for the whole Sales dataset.\n",
    "\n",
    "\n",
    "To make prediction, on an individual Sales value, I write\n",
    "\n",
    "\n",
    "\t\tlm.predict(Xi)\n",
    "        \n",
    "\n",
    "where Xi is the Sales data value of the ith observation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting Advertising values\n",
    "\n",
    "lm.predict(X)[0:5]\n",
    "\n",
    "# Predicting Advertising values on first five Sales values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make an individual prediction using the linear regression model.\n",
    "\n",
    "print(str(lm.predict(24)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression metrics for model performance\n",
    "\n",
    "\n",
    "Now, it is the time to evaluate model performance. \n",
    "\n",
    "For regression problems, there are two ways to compute the model performance. They are RMSE (Root Mean Square Error) and R-Squared Value. These are explained below:-  \n",
    "\n",
    "\n",
    "### RMSE\n",
    "\n",
    "RMSE is the standard deviation of the residuals. So, RMSE gives us the standard deviation of the unexplained variance by the model. It can be calculated by taking square root of Mean Squared Error.\n",
    "RMSE is an absolute measure of fit. It gives us how spread the residuals are, given by the standard deviation of the residuals. The more concentrated the data is around the regression line, the lower the residuals and hence lower the standard deviation of residuals. It results in lower values of RMSE. So, lower values of RMSE indicate better fit of data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print Root Mean Square Error(RMSE)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE value: {:.4f}\".format(rmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  R2 Score\n",
    "\n",
    "\n",
    "R2 Score is another metric to evaluate performance of a regression model. It is also called coefficient of determination. It gives us an idea of goodness of fit for the linear regression models. It indicates the percentage of variance that is explained by the model. \n",
    "\n",
    "\n",
    "Mathematically, \n",
    "\n",
    "\n",
    "R2 Score = Explained Variation/Total Variation\n",
    "\n",
    "\n",
    "In general, the higher the R2 Score value, the better the model fits the data. Usually, its value ranges from 0 to 1. So, we want its value to be as close to 1. Its value can become negative if our model is wrong.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print r2_score\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print (\"R2 Score value: {:.4f}\".format(r2_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation and Conclusion\n",
    "\n",
    "\n",
    "The RMSE value has been found to be 11.2273. It means the standard deviation for our prediction is 11.2273. So, sometimes we expect the predictions to be off by more than 11.2273 and other times we expect less than 11.2273. So, the model is not good fit to the data. \n",
    "\n",
    "\n",
    "In business decisions, the benchmark for the R2 score value is 0.7. It means if R2 score value >= 0.7, then the model is good enough to deploy on unseen data whereas if R2 score value < 0.7, then the model is not good enough to deploy. Our R2 score value has been found to be .5789. It means that this model explains 57.89 % of the variance in our dependent variable. So, the R2 score value confirms that the model is not good enough to deploy because it does not provide good fit to the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Regression Line\n",
    "\n",
    "\n",
    "plt.scatter(X, y, color = 'blue', label='Scatter Plot')\n",
    "plt.plot(X_test, y_pred, color = 'black', linewidth=3, label = 'Regression Line')\n",
    "plt.title('Relationship between Sales and Advertising')\n",
    "plt.xlabel('Sales')\n",
    "plt.ylabel('Advertising')\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual analysis\n",
    "\n",
    "\n",
    "\n",
    "A linear regression model may not represent the data appropriately. The model may be a poor fit to the data. So, we should validate our model by defining and examining residual plots.\n",
    "\n",
    "The difference between the observed value of the dependent variable (y) and the predicted value (ŷi) is called the residual and is denoted by e. The scatter-plot of these residuals is called residual plot.\n",
    "\n",
    "If the data points in a residual plot are randomly dispersed around horizontal axis and an approximate zero residual mean, a linear regression model may be appropriate for the data. Otherwise a non-linear model may be more appropriate.\n",
    "\n",
    "If we take a look at the generated ‘Residual errors’ plot, we can clearly see that the train data plot pattern is non-random. Same is the case with the test data plot pattern.\n",
    "So, it suggests a better-fit for a non-linear model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting residual errors\n",
    "\n",
    "plt.scatter(lm.predict(X_train), lm.predict(X_train) - y_train, color = 'red', label = 'Train data')\n",
    "plt.scatter(lm.predict(X_test), lm.predict(X_test) - y_test, color = 'blue', label = 'Test data')\n",
    "plt.hlines(xmin = 0, xmax = 50, y = 0, linewidth = 3)\n",
    "plt.title('Residual errors')\n",
    "plt.legend(loc = 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Overfitting and Underfitting\n",
    "\n",
    "\n",
    "I calculate training set score as 0.2861. Similarly, I calculate test set score as 0.5789. \n",
    "The training set score is very poor. So, the model does not learn the relationships appropriately from the training data. Thus, the model performs poorly on the training data. It is a clear sign of Underfitting. Hence, I validated my finding that the linear regression model does not provide good fit to the data. \n",
    "\n",
    "\n",
    "Underfitting means our model performs poorly on the training data. It means the model does not capture the relationships between the training data. This problem can be improved by increasing model complexity. We should use more powerful models like Polynomial regression to increase model complexity. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Overfitting or Underfitting the data\n",
    "\n",
    "print(\"Training set score: {:.4f}\".format(lm.score(X_train,y_train)))\n",
    "\n",
    "print(\"Test set score: {:.4f}\".format(lm.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for future use\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(lm, 'lm_regressor.pkl')\n",
    "\n",
    "# To load the model\n",
    "\n",
    "# lm2=joblib.load('lm_regressor.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression - Model Assumptions\n",
    "\n",
    "\n",
    "\n",
    "The Linear Regression Model is based on several assumptions which are listed below:-\n",
    "\n",
    "i.\tLinear relationship\n",
    "ii.\tMultivariate normality\n",
    "iii.\tNo or little multicollinearity\n",
    "iv.\tNo auto-correlation\n",
    "v.\tHomoscedasticity\n",
    "\n",
    "\n",
    "### i.\tLinear relationship\n",
    "\n",
    "\n",
    "The relationship between response and feature variables should be linear. This linear relationship assumption can be tested by plotting a scatter-plot between response and feature variables.\n",
    "\n",
    "\n",
    "### ii.\tMultivariate normality\n",
    "\n",
    "The linear regression model requires all variables to be multivariate normal. A multivariate normal distribution means a vector in multiple normally distributed variables, where any linear combination of the variables is also normally distributed.\n",
    "\n",
    "\n",
    "### iii.\tNo or little multicollinearity\n",
    "\n",
    "It is assumed that there is little or no multicollinearity in the data. Multicollinearity occurs when the features (or independent variables) are highly correlated.\n",
    "\n",
    "\n",
    "### iv.\tNo auto-correlation\n",
    "\n",
    "Also, it is assumed that there is little or no auto-correlation in the data. Autocorrelation occurs when the residual errors are not independent from each other.\n",
    "\n",
    "\n",
    "### v.\tHomoscedasticity\n",
    "\n",
    "Homoscedasticity describes a situation in which the error term (that is, the noise in the model) is the same across all values of the independent variables. It means the residuals are same across the regression line. It can be checked by looking at scatter plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\n",
    "The concepts and ideas in this project have been taken from the following websites and books:-\n",
    "\n",
    "i.\tMachine learning notes by Andrew Ng\n",
    "\n",
    "ii.\thttps://en.wikipedia.org/wiki/Linear_regression\n",
    "\n",
    "iii.https://en.wikipedia.org/wiki/Simple_linear_regression\n",
    "\n",
    "iv.\thttps://en.wikipedia.org/wiki/Ordinary_least_squares\n",
    "\n",
    "v.\thttps://en.wikipedia.org/wiki/Root-mean-square_deviation\n",
    "\n",
    "vi.\thttps://en.wikipedia.org/wiki/Coefficient_of_determination\n",
    "\n",
    "vii.https://www.statisticssolutions.com/assumptions-of-linear-regression/\n",
    "\n",
    "viii.Python Data Science Handbook by Jake VanderPlas\n",
    "\n",
    "ix.\tHands-On Machine Learning with Scikit Learn and Tensorflow by Aurilien Geron\n",
    "\n",
    "x.\tIntroduction to Machine Learning with Python by Andreas C Muller and Sarah Guido\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
